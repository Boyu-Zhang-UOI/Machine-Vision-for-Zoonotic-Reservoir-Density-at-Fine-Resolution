{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79786727",
   "metadata": {},
   "source": [
    "## Import libraries (XGB3 environment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fb8347c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.transform import from_origin\n",
    "from rasterio.mask import mask\n",
    "from rasterio.enums import Resampling\n",
    "from shapely.geometry import box\n",
    "from fiona.crs import from_epsg\n",
    "import geopandas as gpd\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import os\n",
    "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold, GridSearchCV, StratifiedKFold, ParameterGrid\n",
    "from scipy import ndimage\n",
    "from sklearn.inspection import PartialDependenceDisplay, partial_dependence\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from plotnine import *\n",
    "from scipy import interpolate\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import itertools\n",
    "import sys\n",
    "sys.version\n",
    "\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import os\n",
    "\n",
    "from math import *\n",
    "\n",
    "#from Tools import *\n",
    "#import Tools\n",
    "exec(open('Tools.py').read())\n",
    "\n",
    "pd.set_option('display.max_columns',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9bbecf",
   "metadata": {},
   "source": [
    "## Create storage directory for fitted models and figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0a1f91e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_grid = 50 ## Spatial block size\n",
    "prefix = 'Fit_all_multigrid1_md1_new' + str(dr_grid)\n",
    "model_path = 'Fitted_models/' + prefix + '/'\n",
    "model_fig_path = 'Fitted_models/' + prefix + '/Figures/'\n",
    "make_dir(model_path)\n",
    "make_dir(model_fig_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0fa279",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7064ee29",
   "metadata": {},
   "source": [
    "## Choose predictors, load and aggregate data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e8d43121",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load dataset\n",
    "All_dat = pd.read_csv('Data/Trap_Data/Clean_Both_Data_By_Trap.csv', low_memory = False)\n",
    "\n",
    "xmin = All_dat.Longitude.min()\n",
    "xmax = All_dat.Longitude.max()\n",
    "ymin = All_dat.Latitude.min()\n",
    "ymax = All_dat.Latitude.max()\n",
    "mean_lat = All_dat.Latitude.mean()\n",
    "dy = dr_grid / 111139\n",
    "\n",
    "\n",
    "all_agg_data = pd.DataFrame()\n",
    "np.random.seed(47)\n",
    "ngrid = 5\n",
    "for ii in range(ngrid):\n",
    "    drll = dr_grid/111139\n",
    "    djx = drll*np.random.random(1)\n",
    "    djy = drll*np.random.random(1)  \n",
    "    All_dat.loc[:,'boxi'] = get_grid(All_dat, drll = dy, \n",
    "                                djx = djx, djy =djy)[0]\n",
    "    agg_data = aggregate_data(All_dat, 'boxi', get_var_names() + ['Longitude', 'Latitude'])\n",
    "    agg_data = agg_data.loc[agg_data.TotTraps > 0,:]\n",
    "    agg_data.loc[:,'gridi'] = ii\n",
    "    all_agg_data = pd.concat((all_agg_data, agg_data))\n",
    "\n",
    "agg_data = all_agg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3acc62e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178e099a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0507ab31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Visit\n",
       "1         2019-09-07\n",
       "2         2019-11-05\n",
       "3         2020-01-08\n",
       "4         2020-03-02\n",
       "5         2020-12-02\n",
       "Jan-04    2004-01-26\n",
       "Jan-05    2005-01-24\n",
       "May-03    2003-05-24\n",
       "May-04    2004-05-20\n",
       "Oct-03    2003-09-23\n",
       "Oct-04    2004-10-03\n",
       "dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "All_dat.groupby('Visit').apply(lambda x: x['Date'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55f42eb",
   "metadata": {},
   "source": [
    "## Set model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "68a61e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of hyperparameters: 96\n"
     ]
    }
   ],
   "source": [
    "town_list = All_dat.Site.unique() \n",
    "max_iters = 2000\n",
    "vary_n_iters =np.arange(50,max_iters, 50).tolist()\n",
    "\n",
    "param_dict = {'eval_metric':['rmse'],\n",
    "              'nthread':[2], \n",
    "              'max_depth':[1], 'subsample':[0.001,0.005,0.01, 0.025, 0.05, 0.1,0.25,0.5], 'n_estimators':[max_iters],\n",
    "              'colsample_bytree':[0.05, 0.1, 0.2, 0.3], 'lambda':[0], 'eta':[0.01],\n",
    "              'test_site': town_list, 'gamma':[0] ,\n",
    "              'dr':[0], 'booster':['gbtree'], 'prec':[True]}\n",
    "# param_dict = {'eval_metric':['rmse'],\n",
    "#               'nthread':[2], \n",
    "#               'max_depth':[4], 'subsample':[0.001,0.005,0.01, 0.025, 0.05, 0.1,0.25,0.5], 'n_estimators':[max_iters],\n",
    "#               'colsample_bytree':[0.05, 0.1, 0.2, 0.3], 'lambda':[0], 'eta':[0.01],\n",
    "#               'test_site': town_list, 'gamma':[0, 0.1, 0.5, 1, 2, 5] ,\n",
    "#               'dr':[0], 'booster':['gbtree'], 'prec':[True]}\n",
    "# param_dict = {'eval_metric':['rmse'],\n",
    "#               'nthread':[2], \n",
    "#               'max_depth':[1], 'subsample':[0.1], 'n_estimators':[max_iters],\n",
    "#               'colsample_bytree':[0.1], 'lambda':[0], 'eta':[0.01],\n",
    "#               'test_site': town_list, 'gamma':[0] ,\n",
    "#               'dr':[0], 'booster':['gbtree'], 'prec':[True]}\n",
    "xgboost_param_names = ['eval_metric', 'nthread', \n",
    "                 'max_depth', 'subsample', 'n_estimators', \n",
    "                 'colsample_bytree', 'lambda', 'eta', 'booster',\n",
    "                       'gamma'\n",
    "                 ]\n",
    "\n",
    "param_grid = ParameterGrid(param_dict)\n",
    "npars = len(param_grid)\n",
    "print('Number of hyperparameters: ' + str(len(param_grid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d11d4547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fit_all_scaled_multigrid1_md1_new50'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6aff171f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Finished parameter set:  0  /  96\n",
      "*** Finished parameter set:  1  /  96\n",
      "*** Finished parameter set:  2  /  96\n",
      "*** Finished parameter set:  3  /  96\n",
      "*** Finished parameter set:  4  /  96\n",
      "*** Finished parameter set:  5  /  96\n",
      "*** Finished parameter set:  6  /  96\n",
      "*** Finished parameter set:  7  /  96\n",
      "*** Finished parameter set:  8  /  96\n",
      "*** Finished parameter set:  9  /  96\n",
      "*** Finished parameter set:  10  /  96\n",
      "*** Finished parameter set:  11  /  96\n",
      "*** Finished parameter set:  12  /  96\n",
      "*** Finished parameter set:  13  /  96\n",
      "*** Finished parameter set:  14  /  96\n",
      "*** Finished parameter set:  15  /  96\n",
      "*** Finished parameter set:  16  /  96\n",
      "*** Finished parameter set:  17  /  96\n",
      "*** Finished parameter set:  18  /  96\n",
      "*** Finished parameter set:  19  /  96\n",
      "*** Finished parameter set:  20  /  96\n",
      "*** Finished parameter set:  21  /  96\n",
      "*** Finished parameter set:  22  /  96\n",
      "*** Finished parameter set:  23  /  96\n",
      "*** Finished parameter set:  24  /  96\n",
      "*** Finished parameter set:  25  /  96\n",
      "*** Finished parameter set:  26  /  96\n",
      "*** Finished parameter set:  27  /  96\n",
      "*** Finished parameter set:  28  /  96\n",
      "*** Finished parameter set:  29  /  96\n",
      "*** Finished parameter set:  30  /  96\n",
      "*** Finished parameter set:  31  /  96\n",
      "*** Finished parameter set:  32  /  96\n",
      "*** Finished parameter set:  33  /  96\n",
      "*** Finished parameter set:  34  /  96\n",
      "*** Finished parameter set:  35  /  96\n",
      "*** Finished parameter set:  36  /  96\n",
      "*** Finished parameter set:  37  /  96\n",
      "*** Finished parameter set:  38  /  96\n",
      "*** Finished parameter set:  39  /  96\n",
      "*** Finished parameter set:  40  /  96\n",
      "*** Finished parameter set:  41  /  96\n",
      "*** Finished parameter set:  42  /  96\n",
      "*** Finished parameter set:  43  /  96\n",
      "*** Finished parameter set:  44  /  96\n",
      "*** Finished parameter set:  45  /  96\n",
      "*** Finished parameter set:  46  /  96\n",
      "*** Finished parameter set:  47  /  96\n",
      "*** Finished parameter set:  48  /  96\n",
      "*** Finished parameter set:  49  /  96\n",
      "*** Finished parameter set:  50  /  96\n",
      "*** Finished parameter set:  51  /  96\n",
      "*** Finished parameter set:  52  /  96\n",
      "*** Finished parameter set:  53  /  96\n",
      "*** Finished parameter set:  54  /  96\n",
      "*** Finished parameter set:  55  /  96\n",
      "*** Finished parameter set:  56  /  96\n",
      "*** Finished parameter set:  57  /  96\n",
      "*** Finished parameter set:  58  /  96\n",
      "*** Finished parameter set:  59  /  96\n",
      "*** Finished parameter set:  60  /  96\n",
      "*** Finished parameter set:  61  /  96\n",
      "*** Finished parameter set:  62  /  96\n",
      "*** Finished parameter set:  63  /  96\n",
      "*** Finished parameter set:  64  /  96\n",
      "*** Finished parameter set:  65  /  96\n",
      "*** Finished parameter set:  66  /  96\n",
      "*** Finished parameter set:  67  /  96\n",
      "*** Finished parameter set:  68  /  96\n",
      "*** Finished parameter set:  69  /  96\n",
      "*** Finished parameter set:  70  /  96\n",
      "*** Finished parameter set:  71  /  96\n",
      "*** Finished parameter set:  72  /  96\n",
      "*** Finished parameter set:  73  /  96\n",
      "*** Finished parameter set:  74  /  96\n",
      "*** Finished parameter set:  75  /  96\n",
      "*** Finished parameter set:  76  /  96\n",
      "*** Finished parameter set:  77  /  96\n",
      "*** Finished parameter set:  78  /  96\n",
      "*** Finished parameter set:  79  /  96\n",
      "*** Finished parameter set:  80  /  96\n",
      "*** Finished parameter set:  81  /  96\n",
      "*** Finished parameter set:  82  /  96\n",
      "*** Finished parameter set:  83  /  96\n",
      "*** Finished parameter set:  84  /  96\n",
      "*** Finished parameter set:  85  /  96\n",
      "*** Finished parameter set:  86  /  96\n",
      "*** Finished parameter set:  87  /  96\n",
      "*** Finished parameter set:  88  /  96\n",
      "*** Finished parameter set:  89  /  96\n",
      "*** Finished parameter set:  90  /  96\n",
      "*** Finished parameter set:  91  /  96\n",
      "*** Finished parameter set:  92  /  96\n",
      "*** Finished parameter set:  93  /  96\n",
      "*** Finished parameter set:  94  /  96\n",
      "*** Finished parameter set:  95  /  96\n"
     ]
    }
   ],
   "source": [
    "## Set up validation fold structure\n",
    "nfolds = 3\n",
    "val_sgkf = GroupKFold(n_splits=nfolds-1)\n",
    "\n",
    "## Loop through hyperparameters, fit models, store results in store_summ\n",
    "store_summ = list()\n",
    "\n",
    "for param_i, param in enumerate(param_grid): \n",
    "    \n",
    "    ## Retrieve the training and validation data only\n",
    "    test_sites = [param['test_site']]\n",
    "    X_trainval, y_trainval, W_trainval, trainval_dat, test_dat = get_trainval_data(dataset = agg_data, \n",
    "                                                                         test_sites = test_sites, \n",
    "                                                                        response = 'TS_Mn', \n",
    "                                                                        weight = 'TotTraps')\n",
    "    if param['prec']:\n",
    "        col_names = get_var_names(prec_flag = True)\n",
    "    else:\n",
    "        col_names = get_var_names(prec_flag = False)\n",
    "    \n",
    "    test_xvals = test_dat.loc[:,col_names]\n",
    "    test_yvals = test_dat.loc[:,'TS_Mn']\n",
    "    test_wvals = test_dat.loc[:,'TotTraps']    \n",
    "\n",
    "    ## Create k-fold CV splitter\n",
    "    fold_gen = val_sgkf.split(trainval_dat.Site, trainval_dat.TS_Mn, \n",
    "                              groups = trainval_dat.Site)\n",
    "\n",
    "    ## Extract xgboost parameters\n",
    "    xgboost_params = {k: param[k] for k in (xgboost_param_names)}        \n",
    "    xgboost_params['eval_metric'] = ['rmse', 'mae']\n",
    "    for train_index, val_index in fold_gen: \n",
    "        \n",
    "        val_site = trainval_dat.Site.loc[val_index].unique()[0]\n",
    "        train_site = trainval_dat.Site.loc[train_index].unique()[0]\n",
    "        \n",
    "        train_xvals = X_trainval.loc[train_index, col_names]    \n",
    "        train_yvals = y_trainval.loc[train_index]\n",
    "        train_wvals = W_trainval.loc[train_index]   \n",
    "        \n",
    "        train_dat_set, train_w_set = get_eval_sets(trainval_dat.iloc[train_index], col_names)\n",
    "        val_dat_set, val_w_set = get_eval_sets(trainval_dat.iloc[val_index], col_names)\n",
    "        test_dat_set, test_w_set = get_eval_sets(test_dat, col_names)\n",
    "        \n",
    "        eval_sets = train_dat_set + val_dat_set + test_dat_set\n",
    "        weight_sets = train_w_set + val_w_set + test_w_set\n",
    "        \n",
    "        xgb_model = xgb.XGBRegressor(objective = 'reg:logistic', **xgboost_params)\n",
    "\n",
    "        xgb_model.fit(X = train_xvals, y = train_yvals, \n",
    "                     sample_weight = train_wvals, \n",
    "                     eval_set = eval_sets, \n",
    "                      sample_weight_eval_set = weight_sets, \n",
    "                     verbose = False)                     \n",
    "        xgb_model.save_model(model_path + 'par_' + str(param_i) + '_fold_' + str(val_site) + '.txt')        \n",
    "        \n",
    "        for n_iter in [iters for iters in vary_n_iters if (iters <= param['n_estimators'])]:\n",
    "            store_summ_new = [param_i, train_site, val_site, n_iter]\n",
    "            \n",
    "            for gridi in range(3*ngrid):\n",
    "                val_name = 'validation_' + str(gridi)\n",
    "                loss = xgb_model.evals_result()[val_name]['mae'][n_iter-1]\n",
    "  \n",
    "                store_summ_new = store_summ_new + [loss]\n",
    "    \n",
    "            add = [param[xx] for xx in list(param.keys())]\n",
    "            store_summ_new += add\n",
    "            store_summ.append(store_summ_new)\n",
    "    print('*** Finished parameter set: ', param_i, ' / ', npars)\n",
    "\n",
    "name_list = ['train','val','test']\n",
    "eval_name_list = [name_list[ii//ngrid] + '_loss' + str(ii%ngrid) for ii in range(3*ngrid)]\n",
    "    \n",
    "col_names = ['param', 'train_site', 'val_site', 'n_iter'] + eval_name_list\n",
    "col_names += list(param.keys())                                                  \n",
    "\n",
    "store_summ_df = pd.DataFrame(store_summ, columns = col_names)\n",
    "\n",
    "store_summ_df.loc[:,'train_loss'] = store_summ_df.loc[:,['train_loss' + str(x) for x in range(nfolds)]].mean(axis = 1)\n",
    "store_summ_df.loc[:,'sdtrain_loss'] = store_summ_df.loc[:,['train_loss' + str(x) for x in range(nfolds)]].std(axis = 1)\n",
    "store_summ_df.loc[:,'val_loss'] = store_summ_df.loc[:,['val_loss' + str(x) for x in range(nfolds)]].mean(axis = 1)\n",
    "store_summ_df.loc[:,'sdval_loss'] = store_summ_df.loc[:,['val_loss' + str(x) for x in range(nfolds)]].std(axis = 1)\n",
    "store_summ_df.loc[:,'test_loss'] = store_summ_df.loc[:,['test_loss' + str(x) for x in range(nfolds)]].mean(axis = 1)\n",
    "store_summ_df.loc[:,'sdtest_loss'] = store_summ_df.loc[:,['test_loss' + str(x) for x in range(nfolds)]].std(axis = 1)\n",
    "\n",
    "store_summ_df.to_csv(model_path + prefix + '_store_summ.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7808edd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e85223",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41be3545",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3978ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
